{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fav_cuisine_coded\n",
      "0     6\n",
      "1    59\n",
      "2    15\n",
      "3     2\n",
      "4    22\n",
      "5    15\n",
      "6     1\n",
      "7     1\n",
      "8     4\n",
      "Name: fav_cuisine_coded, dtype: int64\n",
      "fav_cuisine_coded\n",
      "1    59\n",
      "2    15\n",
      "4    26\n",
      "5    15\n",
      "Name: fav_cuisine_coded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#load file\n",
    "df=pd.read_csv(\"food_coded.csv\")\n",
    "df.head(5)\n",
    "\n",
    "#print(X.columns)\n",
    "#print(y.columns)\n",
    "#print(y.head(5))\n",
    "\n",
    "\n",
    "# Simplying data due to low training data avaialble\n",
    "    # Removing 2,6,7 categroy due to low count\n",
    "    # Adding 8 to 4 because indian food also comes under the umbrella of Asian food\n",
    "    # Removing 0 because they are undecided and have low counts\n",
    "\n",
    "print(df.groupby(['fav_cuisine_coded']).fav_cuisine_coded.count())\n",
    "\n",
    "df.loc[df['fav_cuisine_coded']==8] = 4\n",
    "df=df[df['fav_cuisine_coded'].isin([1,2,4,5])]\n",
    "\n",
    "print(df.groupby(['fav_cuisine_coded']).fav_cuisine_coded.count())\n",
    "\n",
    "# Split it into input features and output \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fav_cuisine_coded', 'calories_day', 'coffee', 'cook', 'drink',\n",
      "       'eating_out', 'employment', 'ethnic_food', 'exercise', 'fruit_day',\n",
      "       'healthy_feeling', 'income', 'nutritional_check', 'parents_cook',\n",
      "       'pay_meal_out', 'veggies_day', 'vitamins', 'indian_food',\n",
      "       'italian_food', 'greek_food', 'persian_food'],\n",
      "      dtype='object')\n",
      "   fav_cuisine_coded  calories_day  coffee  cook  drink  eating_out  \\\n",
      "1                  1           3.0       2   3.0    2.0           2   \n",
      "2                  1           4.0       2   1.0    1.0           2   \n",
      "4                  1           2.0       2   1.0    2.0           2   \n",
      "6                  4           3.0       2   2.0    1.0           2   \n",
      "7                  5           3.0       1   3.0    2.0           2   \n",
      "\n",
      "   employment  ethnic_food  exercise  fruit_day  ...  income  \\\n",
      "1         2.0            4       1.0          4  ...     4.0   \n",
      "2         3.0            5       2.0          5  ...     6.0   \n",
      "4         2.0            4       1.0          4  ...     6.0   \n",
      "6         3.0            5       1.0          4  ...     4.0   \n",
      "7         2.0            2       2.0          5  ...     5.0   \n",
      "\n",
      "   nutritional_check  parents_cook  pay_meal_out  veggies_day  vitamins  \\\n",
      "1                  4             1             4            4         2   \n",
      "2                  4             1             3            5         1   \n",
      "4                  3             1             4            4         2   \n",
      "6                  4             2             2            4         1   \n",
      "7                  4             1             5            4         2   \n",
      "\n",
      "   indian_food  italian_food  greek_food  persian_food  \n",
      "1            4             4           4           4.0  \n",
      "2            5             5           5           5.0  \n",
      "4            2             5           4           2.0  \n",
      "6            5             5           5           5.0  \n",
      "7            1             3           3           1.0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#for (i,names) in enumerate(df.columns):\n",
    "    #print (i,\" : \",names)\n",
    "df_sel = df.iloc[:,[26,4,6,10,15,19,20,21,22,30,33,37,45,47,48,57,58,38,39,32,49]]\n",
    "print(df_sel.columns)\n",
    "print(df_sel.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#data cleaning\n",
    "\n",
    "    # Taqi code will come here, i am just getting the column as it is \n",
    "    \n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer.fit(df_sel)\n",
    "X = imputer.transform(df_sel)\n",
    "df_sel_clean = pd.DataFrame(X,columns = df_sel.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardization\n",
    "\n",
    "    # This will be done once data is cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration\n",
    "    # scatter plots\n",
    "    # histograms\n",
    "    # Box plot \n",
    "    # Line chart etc\n",
    "\n",
    "# Just put whatever you think is related to our model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(df_1):\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    \n",
    "    corrMatrix = df.corr()\n",
    "    fig, ax = plt.subplots(figsize=(30,30))\n",
    "    #sns.heatmap(corrMatrix,cmap=ListedColormap(['green','green', 'yellow','red', 'red']), annot=True,linewidths=.5, ax=ax)\n",
    "    sns.heatmap(corrMatrix, annot=True,linewidths=.5, ax=ax)   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix(df_sel_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square_feature_sel(df_1, dep_col_name,total_col_selected):\n",
    "    df_train_chi_ind = df_1.loc[:, df_1.columns != dep_col_name]\n",
    "    df_train_chi_dep = df_1.iloc[:,df_1.columns == dep_col_name]\n",
    "    \n",
    "    #rint(df_train_chi_dep.head(5))\n",
    "    #rint(df_train_chi_ind.head(5))\n",
    "    \n",
    "    \n",
    "    \n",
    "    bestfeatures = SelectKBest(score_func=chi2, k=20)\n",
    "    fit = bestfeatures.fit(df_train_chi_ind,df_train_chi_dep)\n",
    "    \n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(df_train_chi_ind.columns)\n",
    "    \n",
    "    #concat two dataframes for better visualization \n",
    "    \n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    \n",
    "    featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "    #print(featureScores.nlargest(20,'Score'))  #print 10 best features\n",
    "    \n",
    "    top_n_columns = featureScores.sort_values('Score',ascending=False).head(total_col_selected).Specs\n",
    "    return top_n_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fav_cuisine_coded', 'coffee', 'ethnic_food', 'exercise',\n",
      "       'healthy_feeling', 'income', 'nutritional_check', 'parents_cook',\n",
      "       'indian_food', 'greek_food', 'persian_food'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#feature selection\n",
    "    # Chi-square (categorical variables)\n",
    "    # Random Forest (overall)\n",
    "    # Correlation (numerical variables)\n",
    "    # use lasso as well \n",
    "# join multiple features\n",
    "\n",
    "\n",
    "# Important step , need to iterate over and over to find suitable features\n",
    "\n",
    "# Currently i am just hand-picking the features and then applying chi-square test and correlation to get top features \n",
    "\n",
    "top_n_cols = chi_square_feature_sel(df_sel_clean,'fav_cuisine_coded',10)\n",
    "top_n_cols=list(top_n_cols)\n",
    "top_n_cols.append('fav_cuisine_coded')\n",
    "\n",
    "df_sel_features =  df_sel_clean[df_sel_clean.columns.intersection(top_n_cols)]\n",
    "\n",
    "print(df_sel_features.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fav_cuisine_coded\n",
      "1.0    41\n",
      "2.0    11\n",
      "4.0    18\n",
      "5.0    10\n",
      "Name: fav_cuisine_coded, dtype: int64\n",
      "fav_cuisine_coded\n",
      "1.0    12\n",
      "2.0     3\n",
      "4.0     5\n",
      "5.0     3\n",
      "Name: fav_cuisine_coded, dtype: int64\n",
      "fav_cuisine_coded\n",
      "1.0    6\n",
      "2.0    1\n",
      "4.0    3\n",
      "5.0    2\n",
      "Name: fav_cuisine_coded, dtype: int64\n",
      "    coffee  ethnic_food  exercise  healthy_feeling  income  nutritional_check  \\\n",
      "80     2.0          5.0       1.0              7.0     2.0                5.0   \n",
      "45     2.0          2.0       1.0              8.0     1.0                5.0   \n",
      "\n",
      "    parents_cook  indian_food  greek_food  persian_food  \n",
      "80           1.0          5.0         5.0           5.0  \n",
      "45           1.0          1.0         1.0           1.0  \n"
     ]
    }
   ],
   "source": [
    "#test-train split using stratification\n",
    "\n",
    "# STRATIFIED SAMPLING \n",
    "X = df_sel_features.loc[:, df_sel_features.columns != 'fav_cuisine_coded']\n",
    "y = df_sel_features[['fav_cuisine_coded']]\n",
    "\n",
    "X_train, tempX_test, y_train, tempY_test = train_test_split(X, y,stratify=y,test_size=0.30)\n",
    "x_val, x_test, y_val, y_test = train_test_split(tempX_test, tempY_test,stratify=tempY_test,test_size=0.64)\n",
    "\n",
    "# Training Set : X_train, y_train\n",
    "# Validation Set : x_val ,  y_val\n",
    "# Testing Set : x_test , y_test\n",
    "\n",
    "\n",
    "print(y_train.groupby(['fav_cuisine_coded']).fav_cuisine_coded.count())\n",
    "print(y_test.groupby(['fav_cuisine_coded']).fav_cuisine_coded.count())\n",
    "print(y_val.groupby(['fav_cuisine_coded']).fav_cuisine_coded.count())\n",
    "print(X_train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 5. 1. 2. 1. 1. 4. 4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.43478260869565216"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model implementation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "softmax_reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", C=10, random_state=42)\n",
    "softmax_reg.fit(X_train, y_train)\n",
    "\n",
    "c_est = softmax_reg.predict(x_val)\n",
    "probs = softmax_reg.predict_proba(x_val)\n",
    "print(c_est)\n",
    "\n",
    "#print(x_val)\n",
    "#print(y_val)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_val, c_est)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "c_est = softmax_reg.predict(x_test)\n",
    "accuracy_score(y_test, c_est)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#cross validation to test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search for finding right hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation function & Thresholding\n",
    "    # Loop through thresholds to get best performance\n",
    "    # If implementing One vs ALl , use baseline performance and compare it with other.\n",
    "    # Precision, Recall, Accuracy, ROC curve, F1 score\n",
    "    # Bin Sampling \n",
    "    # Lift measure\n",
    "    # Migth use R^2 , not sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final hold-out sample testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it is underperforming \n",
    "    #use other model lile (Logistic Regression{One vs All}) <- Try this definitely\n",
    "    # Change feature selection method\n",
    "    # Use l1 unstead of l2 or reduce L2 penalty\n",
    "    \n",
    "# If it is overperforming\n",
    "    # use strict l2\n",
    "    # go back to simple one vs all model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
